{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Causal Discovery Example\n",
    "\n",
    "This notebook demonstrates causal network discovery using the **Poisson** information method with synthetic count data.\n",
    "\n",
    "## Overview\n",
    "- Generate synthetic Poisson time series with known causal structure\n",
    "- Visualize the count dynamics and network structure\n",
    "- Apply causal discovery using Poisson conditional mutual information\n",
    "- Evaluate performance using ROC-AUC metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import causal discovery components\n",
    "from causalentropy.core.discovery import discover_network\n",
    "from causalentropy.datasets.synthetic import poisson_coupled_oscillators\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Ground Truth Network\n",
    "\n",
    "We'll create a directed graph that represents the true causal relationships for our Poisson process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ground truth network\n",
    "n_nodes = 6\n",
    "seed = 42\n",
    "\n",
    "# Create a network with interesting structure for Poisson processes\n",
    "np.random.seed(seed)\n",
    "G_true = nx.DiGraph()\n",
    "G_true.add_nodes_from(range(n_nodes))\n",
    "\n",
    "# Add causal edges that create interesting count dynamics\n",
    "edges = [(0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 5)]\n",
    "G_true.add_edges_from(edges)\n",
    "\n",
    "print(f\"Ground truth network has {G_true.number_of_nodes()} nodes and {G_true.number_of_edges()} edges\")\n",
    "print(f\"Edges: {list(G_true.edges())}\")\n",
    "\n",
    "# Get adjacency matrix for later comparison\n",
    "A_true = nx.adjacency_matrix(G_true).toarray()\n",
    "print(f\"\\nGround truth adjacency matrix:\")\n",
    "print(A_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Poisson Time Series\n",
    "\n",
    "Generate count data where each node's rate depends on its neighbors' previous counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic Poisson time series\n",
    "T = 200  # Time series length\n",
    "lambda_base = 3.0  # Base Poisson rate\n",
    "coupling_strength = 0.5  # How much neighbors influence the rate\n",
    "\n",
    "# Generate data using our custom Poisson generator\n",
    "data, A_generated = poisson_coupled_oscillators(\n",
    "    n=n_nodes,\n",
    "    T=T,\n",
    "    G=G_true,  # Use our predefined network\n",
    "    lambda_base=lambda_base,\n",
    "    coupling_strength=coupling_strength,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "print(f\"Generated Poisson time series data with shape: {data.shape}\")\n",
    "print(f\"Data statistics:\")\n",
    "print(f\"  Mean: {np.mean(data):.3f}\")\n",
    "print(f\"  Std:  {np.std(data):.3f}\")\n",
    "print(f\"  Range: [{np.min(data):.0f}, {np.max(data):.0f}]\")\n",
    "print(f\"  Data type: {data.dtype} (discrete counts)\")\n",
    "\n",
    "# Verify that generated adjacency matches our ground truth\n",
    "print(f\"\\nAdjacency matrix match: {np.array_equal(A_true, A_generated.astype(int))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Poisson Time Series Data\n",
    "\n",
    "Plot the count dynamics to understand the characteristics of Poisson data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series for all variables\n",
    "fig, axes = plt.subplots(n_nodes, 1, figsize=(14, 10), sharex=True)\n",
    "fig.suptitle('Poisson Coupled Count Processes', fontsize=16, fontweight='bold')\n",
    "\n",
    "time = np.arange(T)\n",
    "colors = sns.color_palette(\"viridis\", n_nodes)\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    # Plot as step function to emphasize discrete nature\n",
    "    axes[i].step(time, data[:, i], color=colors[i], alpha=0.8, linewidth=1.5, where='post')\n",
    "    axes[i].fill_between(time, 0, data[:, i], color=colors[i], alpha=0.3, step='post')\n",
    "    \n",
    "    axes[i].set_ylabel(f'Count X{i}', fontweight='bold')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_val = np.mean(data[:, i])\n",
    "    axes[i].axhline(mean_val, color='red', linestyle='--', alpha=0.7, \n",
    "                   label=f'Mean: {mean_val:.1f}')\n",
    "    axes[i].legend(fontsize=8, loc='upper right')\n",
    "    \n",
    "    # Set y-axis to show integer ticks\n",
    "    axes[i].set_yticks(range(int(np.min(data[:, i])), int(np.max(data[:, i])) + 1, max(1, int(np.max(data[:, i])) // 5)))\n",
    "\n",
    "axes[-1].set_xlabel('Time', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram of counts for each variable\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "fig.suptitle('Distribution of Poisson Counts', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    counts = data[:, i]\n",
    "    axes[i].hist(counts, bins=range(int(np.min(counts)), int(np.max(counts)) + 2), \n",
    "                alpha=0.7, color=colors[i], edgecolor='black', linewidth=0.5)\n",
    "    axes[i].set_title(f'X{i} (λ≈{np.mean(counts):.1f})', fontweight='bold')\n",
    "    axes[i].set_xlabel('Count')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Overlay theoretical Poisson distribution\n",
    "    x_theory = np.arange(int(np.max(counts)) + 1)\n",
    "    poisson_pmf = np.exp(-np.mean(counts)) * (np.mean(counts) ** x_theory) / np.array([np.math.factorial(x) for x in x_theory])\n",
    "    axes[i].plot(x_theory, poisson_pmf * len(counts), 'r-', alpha=0.8, linewidth=2, \n",
    "                label=f'Poisson(λ={np.mean(counts):.1f})')\n",
    "    axes[i].legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Ground Truth Network\n",
    "\n",
    "Display the true causal network structure that generates the count dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground truth network\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create layout that shows the flow structure\n",
    "pos = nx.spring_layout(G_true, seed=seed, k=3, iterations=50)\n",
    "\n",
    "# Draw network with emphasis on count-based coupling\n",
    "node_sizes = [1500 + 200 * np.mean(data[:, i]) for i in range(n_nodes)]\n",
    "nx.draw_networkx_nodes(G_true, pos, node_color='lightcoral', \n",
    "                       node_size=node_sizes, alpha=0.8)\n",
    "nx.draw_networkx_edges(G_true, pos, edge_color='darkred', \n",
    "                       arrows=True, arrowsize=25, width=3, alpha=0.7)\n",
    "nx.draw_networkx_labels(G_true, pos, {i: f'X{i}\\n(λ≈{np.mean(data[:, i]):.1f})' for i in range(n_nodes)},\n",
    "                        font_size=10, font_weight='bold')\n",
    "\n",
    "plt.title('Ground Truth Causal Network\\n(Poisson Count Data)\\nNode size ∝ mean count rate', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print network statistics\n",
    "print(\"Ground Truth Network Statistics:\")\n",
    "print(f\"  Nodes: {G_true.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G_true.number_of_edges()}\")\n",
    "print(f\"  Edge density: {nx.density(G_true):.3f}\")\n",
    "print(f\"  Is DAG: {nx.is_directed_acyclic_graph(G_true)}\")\n",
    "print(f\"  Average count rates: {[f'X{i}: {np.mean(data[:, i]):.1f}' for i in range(n_nodes)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply Causal Discovery with Poisson Method\n",
    "\n",
    "Use the Poisson information method to discover causal relationships from the count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply causal discovery with Poisson method\n",
    "print(\"Applying causal discovery with Poisson information method...\")\n",
    "print(\"This method is specifically designed for count data!\\n\")\n",
    "\n",
    "# Test different discovery methods with Poisson information\n",
    "methods_to_test = ['standard', 'alternative']\n",
    "discovered_networks = {}\n",
    "\n",
    "for method in methods_to_test:\n",
    "    print(f\"Running {method} method with Poisson information...\")\n",
    "    \n",
    "    G_discovered = discover_network(\n",
    "        data=data,\n",
    "        method=method,\n",
    "        information='poisson',  # Key: Use Poisson-specific information measure\n",
    "        max_lag=2,\n",
    "        alpha_forward=0.1,  # Slightly more lenient for count data\n",
    "        alpha_backward=0.1,\n",
    "        n_shuffles=100\n",
    "    )\n",
    "    \n",
    "    discovered_networks[method] = G_discovered\n",
    "    print(f\"  Discovered {G_discovered.number_of_edges()} edges\")\n",
    "    print(f\"  Edges: {list(G_discovered.edges())}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Discovered Networks\n",
    "\n",
    "Compare the discovered networks with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of networks\n",
    "fig, axes = plt.subplots(1, len(methods_to_test) + 1, figsize=(6 * (len(methods_to_test) + 1), 6))\n",
    "if len(methods_to_test) == 1:\n",
    "    axes = [axes[0], axes[1]]\n",
    "\n",
    "# Plot ground truth\n",
    "ax = axes[0]\n",
    "nx.draw_networkx_nodes(G_true, pos, node_color='lightcoral', \n",
    "                       node_size=1200, alpha=0.8, ax=ax)\n",
    "nx.draw_networkx_edges(G_true, pos, edge_color='darkred', \n",
    "                       arrows=True, arrowsize=20, width=2.5, alpha=0.7, ax=ax)\n",
    "nx.draw_networkx_labels(G_true, pos, {i: f'X{i}' for i in range(n_nodes)},\n",
    "                        font_size=12, font_weight='bold', ax=ax)\n",
    "ax.set_title('Ground Truth\\n(Poisson Coupling)', fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot discovered networks\n",
    "colors = ['lightsteelblue', 'lightgreen']\n",
    "edge_colors = ['darkblue', 'darkgreen']\n",
    "\n",
    "for i, (method, G_disc) in enumerate(discovered_networks.items()):\n",
    "    ax = axes[i + 1]\n",
    "    \n",
    "    # Convert node names back to integers\n",
    "    G_disc_int = nx.DiGraph()\n",
    "    G_disc_int.add_nodes_from(range(n_nodes))\n",
    "    for edge in G_disc.edges():\n",
    "        src = int(edge[0].replace('X', '')) if 'X' in str(edge[0]) else int(edge[0])\n",
    "        dst = int(edge[1].replace('X', '')) if 'X' in str(edge[1]) else int(edge[1])\n",
    "        G_disc_int.add_edge(src, dst)\n",
    "    \n",
    "    nx.draw_networkx_nodes(G_disc_int, pos, node_color=colors[i], \n",
    "                           node_size=1200, alpha=0.8, ax=ax)\n",
    "    nx.draw_networkx_edges(G_disc_int, pos, edge_color=edge_colors[i], \n",
    "                           arrows=True, arrowsize=20, width=2.5, alpha=0.7, ax=ax)\n",
    "    nx.draw_networkx_labels(G_disc_int, pos, {i: f'X{i}' for i in range(n_nodes)},\n",
    "                            font_size=12, font_weight='bold', ax=ax)\n",
    "    ax.set_title(f'Discovered\\n({method})', fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Network Comparison: Poisson Information Method', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show edge comparison table\n",
    "print(\"\\nEDGE COMPARISON:\")\n",
    "print(\"=\"*40)\n",
    "true_edges = set(G_true.edges())\n",
    "print(f\"Ground Truth Edges: {true_edges}\")\n",
    "\n",
    "for method, G_disc in discovered_networks.items():\n",
    "    # Convert discovered edges to integer format\n",
    "    disc_edges = set()\n",
    "    for edge in G_disc.edges():\n",
    "        src = int(edge[0].replace('X', '')) if 'X' in str(edge[0]) else int(edge[0])\n",
    "        dst = int(edge[1].replace('X', '')) if 'X' in str(edge[1]) else int(edge[1])\n",
    "        disc_edges.add((src, dst))\n",
    "    \n",
    "    print(f\"{method.capitalize()} Discovered: {disc_edges}\")\n",
    "    \n",
    "    # Calculate overlap\n",
    "    correct = true_edges.intersection(disc_edges)\n",
    "    missed = true_edges - disc_edges\n",
    "    false_positive = disc_edges - true_edges\n",
    "    \n",
    "    print(f\"  ✓ Correct: {correct}\")\n",
    "    print(f\"  ✗ Missed: {missed}\")\n",
    "    print(f\"  ⚠ False Pos: {false_positive}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate ROC-AUC Performance\n",
    "\n",
    "Evaluate the performance of the Poisson method using ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc_auc_poisson(true_adj, discovered_graph):\n",
    "    \"\"\"Calculate ROC-AUC for Poisson method network discovery.\"\"\"\n",
    "    n = true_adj.shape[0]\n",
    "    \n",
    "    # Convert discovered graph to adjacency matrix\n",
    "    G_int = nx.DiGraph()\n",
    "    G_int.add_nodes_from(range(n))\n",
    "    for edge in discovered_graph.edges():\n",
    "        src = int(edge[0].replace('X', '')) if 'X' in str(edge[0]) else int(edge[0])\n",
    "        dst = int(edge[1].replace('X', '')) if 'X' in str(edge[1]) else int(edge[1])\n",
    "        G_int.add_edge(src, dst)\n",
    "    \n",
    "    discovered_adj = nx.adjacency_matrix(G_int, nodelist=range(n)).toarray()\n",
    "    \n",
    "    # Flatten and remove diagonal\n",
    "    mask = ~np.eye(n, dtype=bool).flatten()\n",
    "    y_true = true_adj.flatten()[mask]\n",
    "    y_scores = discovered_adj.flatten()[mask]\n",
    "    \n",
    "    # Calculate ROC-AUC\n",
    "    if len(np.unique(y_true)) > 1:\n",
    "        auc_score = roc_auc_score(y_true, y_scores)\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "        return auc_score, fpr, tpr\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "# Calculate ROC-AUC for each method\n",
    "results = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "colors_roc = ['blue', 'green']\n",
    "for i, (method, G_disc) in enumerate(discovered_networks.items()):\n",
    "    auc_score, fpr, tpr = calculate_roc_auc_poisson(A_true, G_disc)\n",
    "    \n",
    "    if auc_score is not None:\n",
    "        results[method] = {\n",
    "            'auc': auc_score,\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr\n",
    "        }\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.plot(fpr, tpr, color=colors_roc[i], linewidth=3, \n",
    "                label=f'{method} (AUC = {auc_score:.3f})')\n",
    "        \n",
    "        print(f\"{method.upper()} METHOD (Poisson Information):\")\n",
    "        print(f\"  ROC-AUC Score: {auc_score:.3f}\")\n",
    "        print(f\"  Interpretation: {'Excellent' if auc_score > 0.9 else 'Good' if auc_score > 0.7 else 'Fair' if auc_score > 0.6 else 'Poor'}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{method} method: Cannot calculate AUC (insufficient variation)\")\n",
    "\n",
    "# Plot random performance line\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, linewidth=2, label='Random (AUC = 0.500)')\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=12)\n",
    "plt.title('ROC Curves for Poisson Causal Discovery\\n(Count Data with Poisson Information Method)', \n",
    "          fontweight='bold', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(\"PERFORMANCE SUMMARY - POISSON METHOD\")\n",
    "print(\"=\"*55)\n",
    "print(f\"Ground truth edges: {np.sum(A_true)}\")\n",
    "print(f\"Data characteristics: Count data (mean rate ≈ {np.mean(data):.1f})\")\n",
    "print(f\"Information method: Poisson (optimal for count data)\")\n",
    "print()\n",
    "for method, G_disc in discovered_networks.items():\n",
    "    print(f\"{method.capitalize()} method results:\")\n",
    "    print(f\"  Discovered edges: {G_disc.number_of_edges()}\")\n",
    "    if method in results:\n",
    "        print(f\"  ROC-AUC: {results[method]['auc']:.3f}\")\n",
    "        print(f\"  Performance: {'🟢 Excellent' if results[method]['auc'] > 0.9 else '🟡 Good' if results[method]['auc'] > 0.7 else '🟠 Fair' if results[method]['auc'] > 0.6 else '🔴 Poor'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detailed Performance Analysis\n",
    "\n",
    "Calculate comprehensive performance metrics for the Poisson method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def detailed_performance_analysis_poisson(true_adj, discovered_graph):\n",
    "    \"\"\"Calculate detailed performance metrics for Poisson method.\"\"\"\n",
    "    n = true_adj.shape[0]\n",
    "    \n",
    "    # Convert discovered graph to adjacency matrix\n",
    "    G_int = nx.DiGraph()\n",
    "    G_int.add_nodes_from(range(n))\n",
    "    for edge in discovered_graph.edges():\n",
    "        src = int(edge[0].replace('X', '')) if 'X' in str(edge[0]) else int(edge[0])\n",
    "        dst = int(edge[1].replace('X', '')) if 'X' in str(edge[1]) else int(edge[1])\n",
    "        G_int.add_edge(src, dst)\n",
    "    \n",
    "    discovered_adj = nx.adjacency_matrix(G_int, nodelist=range(n)).toarray()\n",
    "    \n",
    "    # Flatten and remove diagonal\n",
    "    mask = ~np.eye(n, dtype=bool)\n",
    "    y_true = true_adj[mask]\n",
    "    y_pred = discovered_adj[mask]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'true_negatives': tn,\n",
    "        'false_negatives': fn,\n",
    "        'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'accuracy': (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    }\n",
    "\n",
    "# Calculate detailed metrics\n",
    "print(\"\\nDETAILED PERFORMANCE ANALYSIS - POISSON METHOD\")\n",
    "print(\"=\"*60)\n",
    "print(\"📊 This analysis shows how well Poisson information\")\n",
    "print(\"   handles count data compared to generic methods.\\n\")\n",
    "\n",
    "for method, G_disc in discovered_networks.items():\n",
    "    metrics = detailed_performance_analysis_poisson(A_true, G_disc)\n",
    "    \n",
    "    print(f\"🔍 {method.upper()} METHOD WITH POISSON INFORMATION:\")\n",
    "    print(f\"   Precision:    {metrics['precision']:.3f} (What fraction of discovered edges are correct?)\")\n",
    "    print(f\"   Recall:       {metrics['recall']:.3f} (What fraction of true edges were found?)\")\n",
    "    print(f\"   F1-Score:     {metrics['f1_score']:.3f} (Harmonic mean of precision & recall)\")\n",
    "    print(f\"   Specificity:  {metrics['specificity']:.3f} (True negative rate)\")\n",
    "    print(f\"   Accuracy:     {metrics['accuracy']:.3f} (Overall correctness)\")\n",
    "    print(f\"   \")  \n",
    "    print(f\"   Confusion Matrix Details:\")\n",
    "    print(f\"   ✓ True Positives:  {metrics['true_positives']} (correctly found edges)\")\n",
    "    print(f\"   ✗ False Positives: {metrics['false_positives']} (incorrectly added edges)\")\n",
    "    print(f\"   ✓ True Negatives:  {metrics['true_negatives']} (correctly absent edges)\")\n",
    "    print(f\"   ✗ False Negatives: {metrics['false_negatives']} (missed true edges)\")\n",
    "    \n",
    "    if method in results:\n",
    "        print(f\"   📈 ROC-AUC:       {results[method]['auc']:.3f}\")\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Compare with what we'd expect from random discovery\n",
    "n_possible_edges = n_nodes * (n_nodes - 1)  # Exclude self-loops\n",
    "random_precision = G_true.number_of_edges() / n_possible_edges\n",
    "print(f\"📋 BASELINE COMPARISON:\")\n",
    "print(f\"   Random precision would be: {random_precision:.3f}\")\n",
    "print(f\"   Total possible directed edges: {n_possible_edges}\")\n",
    "print(f\"   Ground truth edges: {G_true.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Why Poisson Method Works for Count Data\n",
    "\n",
    "Let's examine why the Poisson information method is particularly suitable for count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data characteristics that make Poisson method appropriate\n",
    "print(\"🧮 POISSON METHOD SUITABILITY ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check Poisson assumptions\n",
    "print(\"📈 DATA CHARACTERISTICS:\")\n",
    "for i in range(n_nodes):\n",
    "    counts = data[:, i]\n",
    "    mean_count = np.mean(counts)\n",
    "    var_count = np.var(counts)\n",
    "    ratio = var_count / mean_count if mean_count > 0 else 0\n",
    "    \n",
    "    print(f\"   X{i}: Mean={mean_count:.2f}, Var={var_count:.2f}, Var/Mean={ratio:.2f}\")\n",
    "    print(f\"       {'✓ Good Poisson fit' if 0.8 <= ratio <= 1.2 else '⚠ Overdispersed' if ratio > 1.2 else '⚠ Underdispersed'}\")\n",
    "\n",
    "print(f\"\\n🎯 WHY POISSON METHOD IS EFFECTIVE HERE:\")\n",
    "print(f\"   • Data are discrete counts (integers ≥ 0)\")\n",
    "print(f\"   • Variance ≈ mean for most variables (Poisson property)\")\n",
    "print(f\"   • Coupling affects rate parameters (biologically realistic)\")\n",
    "print(f\"   • Poisson mutual information captures count dependencies\")\n",
    "\n",
    "print(f\"\\n📊 DATA SUMMARY:\")\n",
    "print(f\"   Time series length: {T}\")\n",
    "print(f\"   Number of count processes: {n_nodes}\")\n",
    "print(f\"   Base rate (λ): {lambda_base}\")\n",
    "print(f\"   Coupling strength: {coupling_strength}\")\n",
    "print(f\"   Data range: [{np.min(data):.0f}, {np.max(data):.0f}]\")\n",
    "print(f\"   All values are non-negative integers: {np.all(data >= 0) and np.all(data == np.round(data))}\")\n",
    "\n",
    "# Visualization of Poisson fit\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Variance vs Mean (should be close to diagonal for Poisson)\n",
    "means = [np.mean(data[:, i]) for i in range(n_nodes)]\n",
    "variances = [np.var(data[:, i]) for i in range(n_nodes)]\n",
    "\n",
    "axes[0].scatter(means, variances, s=100, alpha=0.7, color='red')\n",
    "axes[0].plot([0, max(means)], [0, max(means)], 'k--', alpha=0.5, label='Var = Mean (Perfect Poisson)')\n",
    "for i in range(n_nodes):\n",
    "    axes[0].annotate(f'X{i}', (means[i], variances[i]), xytext=(5, 5), textcoords='offset points')\n",
    "axes[0].set_xlabel('Mean Count', fontweight='bold')\n",
    "axes[0].set_ylabel('Variance', fontweight='bold')\n",
    "axes[0].set_title('Poisson Assumption Check\\n(Variance vs Mean)', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribution comparison for one variable\n",
    "i_example = 0  # Show first variable as example\n",
    "counts = data[:, i_example]\n",
    "unique_counts = np.arange(int(np.max(counts)) + 1)\n",
    "\n",
    "# Observed frequencies\n",
    "observed_freq = np.bincount(counts.astype(int), minlength=len(unique_counts))\n",
    "observed_prob = observed_freq / len(counts)\n",
    "\n",
    "# Theoretical Poisson probabilities\n",
    "lambda_est = np.mean(counts)\n",
    "theoretical_prob = np.exp(-lambda_est) * (lambda_est ** unique_counts) / np.array([np.math.factorial(x) for x in unique_counts])\n",
    "\n",
    "x_pos = np.arange(len(unique_counts))\n",
    "width = 0.35\n",
    "axes[1].bar(x_pos - width/2, observed_prob, width, label=f'Observed X{i_example}', alpha=0.7, color='blue')\n",
    "axes[1].bar(x_pos + width/2, theoretical_prob, width, label=f'Poisson(λ={lambda_est:.1f})', alpha=0.7, color='orange')\n",
    "\n",
    "axes[1].set_xlabel('Count Value', fontweight='bold')\n",
    "axes[1].set_ylabel('Probability', fontweight='bold')\n",
    "axes[1].set_title(f'Distribution Comparison: X{i_example}\\n(Observed vs Theoretical Poisson)', fontweight='bold')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(unique_counts)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions\n",
    "\n",
    "Summary of the Poisson causal discovery experiment and key insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"🎯 EXPERIMENT CONCLUSIONS - POISSON CAUSAL DISCOVERY\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "print(f\"\\n📊 DATA CHARACTERISTICS:\")\n",
    "print(f\"  • Time series length: {T}\")\n",
    "print(f\"  • Number of count processes: {n_nodes}\")\n",
    "print(f\"  • Ground truth edges: {G_true.number_of_edges()}\")\n",
    "print(f\"  • Data type: Discrete counts (Poisson-distributed)\")\n",
    "print(f\"  • Base rate: λ = {lambda_base}\")\n",
    "print(f\"  • Coupling mechanism: Rate modulation by neighbor counts\")\n",
    "\n",
    "print(f\"\\n🔍 DISCOVERY RESULTS:\")\n",
    "best_method = None\n",
    "best_auc = 0\n",
    "\n",
    "for method, G_disc in discovered_networks.items():\n",
    "    auc_val = results.get(method, {}).get('auc', 0)\n",
    "    performance_level = ('🟢 Excellent' if auc_val > 0.9 else \n",
    "                        '🟡 Good' if auc_val > 0.7 else \n",
    "                        '🟠 Fair' if auc_val > 0.6 else '🔴 Poor')\n",
    "    print(f\"  • {method.capitalize()} method: {G_disc.number_of_edges()} edges discovered\")\n",
    "    print(f\"    ROC-AUC = {auc_val:.3f} {performance_level}\")\n",
    "    \n",
    "    if auc_val > best_auc:\n",
    "        best_auc = auc_val\n",
    "        best_method = method\n",
    "\n",
    "print(f\"\\n🏆 BEST PERFORMING METHOD: {best_method.upper() if best_method else 'None'}\")\n",
    "if best_method and best_method in results:\n",
    "    print(f\"  • ROC-AUC Score: {best_auc:.3f}\")\n",
    "    print(f\"  • Edges discovered: {discovered_networks[best_method].number_of_edges()}\")\n",
    "    print(f\"  • Performance level: {'🟢 Excellent' if best_auc > 0.9 else '🟡 Good' if best_auc > 0.7 else '🟠 Fair' if best_auc > 0.6 else '🔴 Poor'}\")\n",
    "\n",
    "print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "print(f\"  • ✅ Poisson method is specifically designed for count data\")\n",
    "print(f\"  • ✅ Captures dependencies in discrete event processes\")\n",
    "print(f\"  • ✅ Handles rate-based coupling mechanisms naturally\")\n",
    "print(f\"  • ⚠️  Performance depends on signal-to-noise ratio in coupling\")\n",
    "print(f\"  • ⚠️  May struggle with very sparse counts or overdispersion\")\n",
    "\n",
    "print(f\"\\n🧮 POISSON METHOD ADVANTAGES:\")\n",
    "print(f\"  • Respects discrete nature of count data\")\n",
    "print(f\"  • Uses appropriate probability distributions\")\n",
    "print(f\"  • Better than Gaussian methods for count processes\")\n",
    "print(f\"  • Captures rate dependencies effectively\")\n",
    "\n",
    "print(f\"\\n📈 WHEN TO USE POISSON METHOD:\")\n",
    "print(f\"  • Data are non-negative integer counts\")\n",
    "print(f\"  • Variance approximately equals mean\")\n",
    "print(f\"  • Process involves event counting or rates\")\n",
    "print(f\"  • Examples: Gene expression, neural spikes, web clicks\")\n",
    "\n",
    "print(f\"\\n📝 RECOMMENDATIONS:\")\n",
    "print(f\"  • Use Poisson method for any count-based time series\")\n",
    "print(f\"  • Check variance/mean ratio to validate Poisson assumption\")\n",
    "print(f\"  • Consider negative binomial method if data is overdispersed\")\n",
    "print(f\"  • Ensure sufficient data length for reliable discovery\")\n",
    "\n",
    "print(\"\\n🎉 Poisson causal discovery experiment completed successfully!\")\n",
    "print(\"   This method provides a principled approach for count data analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
